{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f7349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manipulação de dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Bibliotecas utilitárias para preparar pipelines de dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import keras.utils\n",
    "\n",
    "# Pra normalizar os dados\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "## Bibliotecas de aprendizado de máquina\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "## Bibliotecas e métricas\n",
    "from sklearn.metrics import confusion_matrix,roc_curve, auc, accuracy_score, recall_score, precision_score\n",
    "\n",
    "## Bibliotecas de apresentação\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns ## Trocar por matplotlib\n",
    "import plotly.express as px\n",
    "\n",
    "## Bibliotecas úteis\n",
    "import itertools\n",
    "from itertools import cycle\n",
    "from scipy import interp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423310dd",
   "metadata": {},
   "source": [
    "## Definindo algumas variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15328f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"results/dados_ideal_size40.csv\"\n",
    "CLASS_NAMES = [0,1]\n",
    "UNECESSARY = ['Unnamed: 0']\n",
    "TARGET = 'class'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f659492c",
   "metadata": {},
   "source": [
    "## Funções necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19160f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(path):\n",
    "    try:\n",
    "        temp_df = pd.read_csv(path)\n",
    "        print(\"Arquivo localizado\")\n",
    "        return temp_df\n",
    "    except:\n",
    "        raise SystemError(\"Não foi possível localizar o arquivo\")\n",
    "    \n",
    "def make_model(output_bias=None, input_shape = 1, output_layers = 1):\n",
    "    METRICS = [\n",
    "      keras.metrics.SensitivityAtSpecificity(name='Sen', specificity= 0.5),\n",
    "      keras.metrics.SpecificityAtSensitivity(name='Spe', sensitivity = 0.5),\n",
    "      keras.metrics.BinaryAccuracy(name='Acc'),\n",
    "      keras.metrics.AUC(name='AUC')\n",
    "    ]\n",
    "\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "          keras.layers.Dense( input_shape, activation='relu', input_shape=(input_shape,)),\n",
    "          keras.layers.Dense( 32, activation='relu'),\n",
    "          keras.layers.Dropout(0.2),\n",
    "          keras.layers.Dense( 32, activation='relu'),\n",
    "          keras.layers.Dropout(0.2),\n",
    "          #keras.layers.Dense( 16, activation='relu'),\n",
    "          #keras.layers.Dropout(0.2),\n",
    "          #keras.layers.Dense( 16, activation='relu', input_shape=(32,)), keras.layers.Dropout(0.1),\n",
    "          #keras.layers.Dense( 4, activation='relu', input_shape=(16,)), keras.layers.Dropout(0.1),\n",
    "          keras.layers.Dense( 1 , activation='sigmoid', bias_initializer=output_bias),\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=1e-4), #15e-4\n",
    "        loss = keras.losses.BinaryCrossentropy(),\n",
    "        metrics = METRICS\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def SaveResult(path,resultado,classe):\n",
    "    f = open('resultados.txt','a')\n",
    "    f.write('\\n')\n",
    "    f.write(str(classe))\n",
    "    f.write('\\n')\n",
    "    f.write(path)\n",
    "    f.write('\\n')\n",
    "    f.write(str(resultado))\n",
    "    f.write(\"\\n \\n################################# \\n\")\n",
    "    f.close()\n",
    "\n",
    "def gencsv(resultados):\n",
    "    f = open('resultados.csv','a')\n",
    "    for i in range(5):\n",
    "        f.write(str(resultados[i])+',')\n",
    "    f.write(\"\\n\")\n",
    "    f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae3f980a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m raw_df \u001b[38;5;241m=\u001b[39m load_file(\u001b[43mpath\u001b[49m)\n\u001b[1;32m      2\u001b[0m raw_df \u001b[38;5;241m=\u001b[39m raw_df\u001b[38;5;241m.\u001b[39mdrop([UNECESSARY],axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m clean_df \u001b[38;5;241m=\u001b[39m raw_df\u001b[38;5;241m.\u001b[39mloc[clean_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignalClass\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(CLASS_NAMES)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "raw_df = load_file(path)\n",
    "raw_df = raw_df.drop([UNECESSARY],axis = 1)\n",
    "clean_df = raw_df.loc[clean_df['signalClass'].isin(CLASS_NAMES)]\n",
    "split_by_class = lambda df, rows_target: df.loc[df[TARGET] == rows_target].copy()\n",
    "norm_df = split_by_class(clean_df, rows_target = 0)\n",
    "susp_df  = split_by_class(clean_df, rows_target = 1)\n",
    "print(\"NORM --------- : \", norm_df.shape)\n",
    "print(\"SUSP ---------- : \", susp_df.shape)\n",
    "neg, pos = np.bincount(clean_df['signalClass'])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de31944",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test, x_val, y_val = train_test_split(clean_df, split_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping:\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    verbose=1,\n",
    "    patience=2500,\n",
    "    mode='min',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb5fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executando o Modelo:\n",
    "BATCH_SIZE = None\n",
    "num_epochs = 10000\n",
    "print(\"Execução do modelo iniciada, aguarde...\")\n",
    "model = make_model(output_bias=None, input_shape = x_train.shape[1], output_layers = 1)\n",
    "history = model.fit(\n",
    "    x_train, y_train, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data=(x_val, y_val),\n",
    "    validation_batch_size = BATCH_SIZE,\n",
    "    class_weight=class_weight,\n",
    "    verbose = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a99be6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valores (validação) para as métricas após os pesos serem restaurados\n",
    "model.evaluate(x = x_val, y = y_val, batch_size=None, return_dict=False)\n",
    "\n",
    "# Valores após o Teste\n",
    "print(\"Resultado: Teste\")\n",
    "baseline_results = model.evaluate(x_test, y_test,batch_size = BATCH_SIZE,  verbose=1)\n",
    "SaveResult(DATA_PATH,baseline_results,CLASS_NAMES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
